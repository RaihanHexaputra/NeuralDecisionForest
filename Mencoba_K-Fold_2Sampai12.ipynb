{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428cbaf6-715c-454f-8577-f7e17c07f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a05d713-436b-4036-bbdb-d1d41be29e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pefile==2017.9.3\n",
      "  Using cached pefile-2017.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: future in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pefile==2017.9.3) (0.18.3)\n",
      "Installing collected packages: pefile\n",
      "  Attempting uninstall: pefile\n",
      "    Found existing installation: pefile 2019.4.18\n",
      "    Uninstalling pefile-2019.4.18:\n",
      "      Successfully uninstalled pefile-2019.4.18\n",
      "Successfully installed pefile-2017.9.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pefile==2017.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b29c966-2a29-4427-bc61-10b0f3bd0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pefile==2019.4.18Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached pefile-2019.4.18-py3-none-any.whl\n",
      "Requirement already satisfied: future in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pefile==2019.4.18) (0.18.3)\n",
      "Installing collected packages: pefile\n",
      "  Attempting uninstall: pefile\n",
      "    Found existing installation: pefile 2017.9.3\n",
      "    Uninstalling pefile-2017.9.3:\n",
      "      Successfully uninstalled pefile-2017.9.3\n",
      "Successfully installed pefile-2019.4.18\n"
     ]
    }
   ],
   "source": [
    "pip install pefile==2019.4.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b41b3c8-2fac-44f8-a95a-9ec21e622531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31e6a6f-330b-42eb-9b8f-49fca934a61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\muhammad raihan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf297b3-8b71-4436-a8dd-bf141f4bf34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy\n",
    "import pickle\n",
    "import pefile\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551ed9b3-f785-4358-9d29-303a6372ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset \n",
    "\n",
    "DM = pd.read_csv(\"C:\\\\Users\\\\Muhammad Raihan\\\\Downloads\\\\Obfuscated-MalMem2022.csv\") #DM--> Dataset Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd84181-3839-4172-af11-90fae396c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>202.844444</td>\n",
       "      <td>1694</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>9129</td>\n",
       "      <td>212.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>11.531915</td>\n",
       "      <td>0</td>\n",
       "      <td>242.234043</td>\n",
       "      <td>2074</td>\n",
       "      <td>44.127660</td>\n",
       "      <td>11385</td>\n",
       "      <td>242.234043</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>14.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>288.225000</td>\n",
       "      <td>1932</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>11529</td>\n",
       "      <td>288.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benign</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>264.281250</td>\n",
       "      <td>1445</td>\n",
       "      <td>45.156250</td>\n",
       "      <td>8457</td>\n",
       "      <td>264.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benign</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>11.452381</td>\n",
       "      <td>0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>2067</td>\n",
       "      <td>49.214286</td>\n",
       "      <td>11816</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  pslist.nproc  pslist.nppid  pslist.avg_threads  \\\n",
       "0   Benign            45            17           10.555556   \n",
       "1   Benign            47            19           11.531915   \n",
       "2   Benign            40            14           14.725000   \n",
       "3   Benign            32            13           13.500000   \n",
       "4   Benign            42            16           11.452381   \n",
       "\n",
       "   pslist.nprocs64bit  pslist.avg_handlers  dlllist.ndlls  \\\n",
       "0                   0           202.844444           1694   \n",
       "1                   0           242.234043           2074   \n",
       "2                   0           288.225000           1932   \n",
       "3                   0           264.281250           1445   \n",
       "4                   0           281.333333           2067   \n",
       "\n",
       "   dlllist.avg_dlls_per_proc  handles.nhandles  handles.avg_handles_per_proc  \\\n",
       "0                  38.500000              9129                    212.302326   \n",
       "1                  44.127660             11385                    242.234043   \n",
       "2                  48.300000             11529                    288.225000   \n",
       "3                  45.156250              8457                    264.281250   \n",
       "4                  49.214286             11816                    281.333333   \n",
       "\n",
       "   ...  svcscan.kernel_drivers  svcscan.fs_drivers  svcscan.process_services  \\\n",
       "0  ...                     221                  26                        24   \n",
       "1  ...                     222                  26                        24   \n",
       "2  ...                     222                  26                        27   \n",
       "3  ...                     222                  26                        27   \n",
       "4  ...                     222                  26                        24   \n",
       "\n",
       "   svcscan.shared_process_services  svcscan.interactive_process_services  \\\n",
       "0                              116                                     0   \n",
       "1                              118                                     0   \n",
       "2                              118                                     0   \n",
       "3                              118                                     0   \n",
       "4                              118                                     0   \n",
       "\n",
       "   svcscan.nactive  callbacks.ncallbacks  callbacks.nanonymous  \\\n",
       "0              121                    87                     0   \n",
       "1              122                    87                     0   \n",
       "2              120                    88                     0   \n",
       "3              120                    88                     0   \n",
       "4              124                    87                     0   \n",
       "\n",
       "   callbacks.ngeneric   Class  \n",
       "0                   8  Benign  \n",
       "1                   8  Benign  \n",
       "2                   8  Benign  \n",
       "3                   8  Benign  \n",
       "4                   8  Benign  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menapilkan head (5 Data Teratas)\n",
    "\n",
    "DM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2970c2b0-c8bf-433a-b1dc-44e4ecef9a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58591</th>\n",
       "      <td>Ransomware-Shade-fa03be3078d1b9840f06745f160eb...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>10.108108</td>\n",
       "      <td>0</td>\n",
       "      <td>215.486487</td>\n",
       "      <td>1453</td>\n",
       "      <td>39.270270</td>\n",
       "      <td>7973</td>\n",
       "      <td>215.486487</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58592</th>\n",
       "      <td>Ransomware-Shade-f56687137caf9a67678cde91e4614...</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>9.945946</td>\n",
       "      <td>0</td>\n",
       "      <td>190.216216</td>\n",
       "      <td>1347</td>\n",
       "      <td>36.405405</td>\n",
       "      <td>7038</td>\n",
       "      <td>190.216216</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58593</th>\n",
       "      <td>Ransomware-Shade-faddeea111a25da4d0888f3044ae9...</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>9.842105</td>\n",
       "      <td>0</td>\n",
       "      <td>210.026316</td>\n",
       "      <td>1448</td>\n",
       "      <td>38.105263</td>\n",
       "      <td>7982</td>\n",
       "      <td>215.729730</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58594</th>\n",
       "      <td>Ransomware-Shade-f866c086af2e1d8ebaa6f2c863157...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>10.243243</td>\n",
       "      <td>0</td>\n",
       "      <td>215.513513</td>\n",
       "      <td>1452</td>\n",
       "      <td>39.243243</td>\n",
       "      <td>7974</td>\n",
       "      <td>215.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58595</th>\n",
       "      <td>Ransomware-Shade-955d9af38346c1755527bd196668e...</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>9.868421</td>\n",
       "      <td>0</td>\n",
       "      <td>213.026316</td>\n",
       "      <td>1487</td>\n",
       "      <td>39.131579</td>\n",
       "      <td>8095</td>\n",
       "      <td>213.026316</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Category  pslist.nproc  \\\n",
       "58591  Ransomware-Shade-fa03be3078d1b9840f06745f160eb...            37   \n",
       "58592  Ransomware-Shade-f56687137caf9a67678cde91e4614...            37   \n",
       "58593  Ransomware-Shade-faddeea111a25da4d0888f3044ae9...            38   \n",
       "58594  Ransomware-Shade-f866c086af2e1d8ebaa6f2c863157...            37   \n",
       "58595  Ransomware-Shade-955d9af38346c1755527bd196668e...            38   \n",
       "\n",
       "       pslist.nppid  pslist.avg_threads  pslist.nprocs64bit  \\\n",
       "58591            15           10.108108                   0   \n",
       "58592            14            9.945946                   0   \n",
       "58593            15            9.842105                   0   \n",
       "58594            15           10.243243                   0   \n",
       "58595            15            9.868421                   0   \n",
       "\n",
       "       pslist.avg_handlers  dlllist.ndlls  dlllist.avg_dlls_per_proc  \\\n",
       "58591           215.486487           1453                  39.270270   \n",
       "58592           190.216216           1347                  36.405405   \n",
       "58593           210.026316           1448                  38.105263   \n",
       "58594           215.513513           1452                  39.243243   \n",
       "58595           213.026316           1487                  39.131579   \n",
       "\n",
       "       handles.nhandles  handles.avg_handles_per_proc  ...  \\\n",
       "58591              7973                    215.486487  ...   \n",
       "58592              7038                    190.216216  ...   \n",
       "58593              7982                    215.729730  ...   \n",
       "58594              7974                    215.513513  ...   \n",
       "58595              8095                    213.026316  ...   \n",
       "\n",
       "       svcscan.kernel_drivers  svcscan.fs_drivers  svcscan.process_services  \\\n",
       "58591                     221                  26                        24   \n",
       "58592                     221                  26                        24   \n",
       "58593                     221                  26                        24   \n",
       "58594                     221                  26                        24   \n",
       "58595                     221                  26                        24   \n",
       "\n",
       "       svcscan.shared_process_services  svcscan.interactive_process_services  \\\n",
       "58591                              116                                     0   \n",
       "58592                              116                                     0   \n",
       "58593                              116                                     0   \n",
       "58594                              116                                     0   \n",
       "58595                              116                                     0   \n",
       "\n",
       "       svcscan.nactive  callbacks.ncallbacks  callbacks.nanonymous  \\\n",
       "58591              120                    86                     0   \n",
       "58592              116                    88                     0   \n",
       "58593              120                    88                     0   \n",
       "58594              120                    87                     0   \n",
       "58595              120                    86                     0   \n",
       "\n",
       "       callbacks.ngeneric    Class  \n",
       "58591                   8  Malware  \n",
       "58592                   8  Malware  \n",
       "58593                   8  Malware  \n",
       "58594                   8  Malware  \n",
       "58595                   8  Malware  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan Tail (5 Data Terbawah)\n",
    "\n",
    "DM.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dad8849-6e90-4097-8f5a-558d25e0fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58596</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>5.859600e+04</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>28346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>29298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.394771</td>\n",
       "      <td>14.713837</td>\n",
       "      <td>11.341655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.509819</td>\n",
       "      <td>1810.805447</td>\n",
       "      <td>43.707806</td>\n",
       "      <td>1.025858e+04</td>\n",
       "      <td>249.560958</td>\n",
       "      <td>...</td>\n",
       "      <td>221.406581</td>\n",
       "      <td>25.996245</td>\n",
       "      <td>25.063417</td>\n",
       "      <td>116.879514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.995546</td>\n",
       "      <td>86.905659</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>7.999881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.777249</td>\n",
       "      <td>2.656748</td>\n",
       "      <td>1.588231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.857790</td>\n",
       "      <td>329.782639</td>\n",
       "      <td>5.742023</td>\n",
       "      <td>4.866864e+03</td>\n",
       "      <td>145.999866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991087</td>\n",
       "      <td>0.170790</td>\n",
       "      <td>1.529628</td>\n",
       "      <td>1.550401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.822858</td>\n",
       "      <td>3.134117</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>3.514000e+03</td>\n",
       "      <td>71.139241</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.972973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.725000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>8.393000e+03</td>\n",
       "      <td>209.648228</td>\n",
       "      <td>...</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.963710</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>42.781524</td>\n",
       "      <td>9.287500e+03</td>\n",
       "      <td>247.208951</td>\n",
       "      <td>...</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.861955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.974322</td>\n",
       "      <td>2087.000000</td>\n",
       "      <td>49.605280</td>\n",
       "      <td>1.219300e+04</td>\n",
       "      <td>291.355050</td>\n",
       "      <td>...</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>16.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24845.951220</td>\n",
       "      <td>3443.000000</td>\n",
       "      <td>53.170732</td>\n",
       "      <td>1.047310e+06</td>\n",
       "      <td>33784.193550</td>\n",
       "      <td>...</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category  pslist.nproc  pslist.nppid  pslist.avg_threads  \\\n",
       "count     58596  58596.000000  58596.000000        58596.000000   \n",
       "unique    28346           NaN           NaN                 NaN   \n",
       "top      Benign           NaN           NaN                 NaN   \n",
       "freq      29298           NaN           NaN                 NaN   \n",
       "mean        NaN     41.394771     14.713837           11.341655   \n",
       "std         NaN      5.777249      2.656748            1.588231   \n",
       "min         NaN     21.000000      8.000000            1.650000   \n",
       "25%         NaN     40.000000     12.000000            9.972973   \n",
       "50%         NaN     41.000000     15.000000           11.000000   \n",
       "75%         NaN     43.000000     16.000000           12.861955   \n",
       "max         NaN    240.000000     72.000000           16.818182   \n",
       "\n",
       "        pslist.nprocs64bit  pslist.avg_handlers  dlllist.ndlls  \\\n",
       "count              58596.0         58596.000000   58596.000000   \n",
       "unique                 NaN                  NaN            NaN   \n",
       "top                    NaN                  NaN            NaN   \n",
       "freq                   NaN                  NaN            NaN   \n",
       "mean                   0.0           247.509819    1810.805447   \n",
       "std                    0.0           111.857790     329.782639   \n",
       "min                    0.0            34.962500     670.000000   \n",
       "25%                    0.0           208.725000    1556.000000   \n",
       "50%                    0.0           243.963710    1735.000000   \n",
       "75%                    0.0           289.974322    2087.000000   \n",
       "max                    0.0         24845.951220    3443.000000   \n",
       "\n",
       "        dlllist.avg_dlls_per_proc  handles.nhandles  \\\n",
       "count                58596.000000      5.859600e+04   \n",
       "unique                        NaN               NaN   \n",
       "top                           NaN               NaN   \n",
       "freq                          NaN               NaN   \n",
       "mean                    43.707806      1.025858e+04   \n",
       "std                      5.742023      4.866864e+03   \n",
       "min                      7.333333      3.514000e+03   \n",
       "25%                     38.833333      8.393000e+03   \n",
       "50%                     42.781524      9.287500e+03   \n",
       "75%                     49.605280      1.219300e+04   \n",
       "max                     53.170732      1.047310e+06   \n",
       "\n",
       "        handles.avg_handles_per_proc  ...  svcscan.kernel_drivers  \\\n",
       "count                   58596.000000  ...            58596.000000   \n",
       "unique                           NaN  ...                     NaN   \n",
       "top                              NaN  ...                     NaN   \n",
       "freq                             NaN  ...                     NaN   \n",
       "mean                      249.560958  ...              221.406581   \n",
       "std                       145.999866  ...                1.991087   \n",
       "min                        71.139241  ...               55.000000   \n",
       "25%                       209.648228  ...              221.000000   \n",
       "50%                       247.208951  ...              221.000000   \n",
       "75%                       291.355050  ...              222.000000   \n",
       "max                     33784.193550  ...              222.000000   \n",
       "\n",
       "        svcscan.fs_drivers  svcscan.process_services  \\\n",
       "count         58596.000000              58596.000000   \n",
       "unique                 NaN                       NaN   \n",
       "top                    NaN                       NaN   \n",
       "freq                   NaN                       NaN   \n",
       "mean             25.996245                 25.063417   \n",
       "std               0.170790                  1.529628   \n",
       "min               6.000000                  7.000000   \n",
       "25%              26.000000                 24.000000   \n",
       "50%              26.000000                 24.000000   \n",
       "75%              26.000000                 27.000000   \n",
       "max              26.000000                 27.000000   \n",
       "\n",
       "        svcscan.shared_process_services  svcscan.interactive_process_services  \\\n",
       "count                      58596.000000                               58596.0   \n",
       "unique                              NaN                                   NaN   \n",
       "top                                 NaN                                   NaN   \n",
       "freq                                NaN                                   NaN   \n",
       "mean                         116.879514                                   0.0   \n",
       "std                            1.550401                                   0.0   \n",
       "min                           26.000000                                   0.0   \n",
       "25%                          116.000000                                   0.0   \n",
       "50%                          116.000000                                   0.0   \n",
       "75%                          118.000000                                   0.0   \n",
       "max                          118.000000                                   0.0   \n",
       "\n",
       "        svcscan.nactive  callbacks.ncallbacks  callbacks.nanonymous  \\\n",
       "count      58596.000000          58596.000000          58596.000000   \n",
       "unique              NaN                   NaN                   NaN   \n",
       "top                 NaN                   NaN                   NaN   \n",
       "freq                NaN                   NaN                   NaN   \n",
       "mean         121.995546             86.905659              0.000853   \n",
       "std            2.822858              3.134117              0.029199   \n",
       "min           30.000000             50.000000              0.000000   \n",
       "25%          121.000000             87.000000              0.000000   \n",
       "50%          122.000000             87.000000              0.000000   \n",
       "75%          123.000000             88.000000              0.000000   \n",
       "max          129.000000             89.000000              1.000000   \n",
       "\n",
       "        callbacks.ngeneric   Class  \n",
       "count         58596.000000   58596  \n",
       "unique                 NaN       2  \n",
       "top                    NaN  Benign  \n",
       "freq                   NaN   29298  \n",
       "mean              7.999881     NaN  \n",
       "std               0.010929     NaN  \n",
       "min               7.000000     NaN  \n",
       "25%               8.000000     NaN  \n",
       "50%               8.000000     NaN  \n",
       "75%               8.000000     NaN  \n",
       "max               8.000000     NaN  \n",
       "\n",
       "[11 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan Kesimpulan Atribut Numerik\n",
    "\n",
    "DM.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b58d9c-859f-409a-87d6-e47bf71cfcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58596</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>5.859600e+04</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>28346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>29298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.394771</td>\n",
       "      <td>14.713837</td>\n",
       "      <td>11.341655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.509819</td>\n",
       "      <td>1810.805447</td>\n",
       "      <td>43.707806</td>\n",
       "      <td>1.025858e+04</td>\n",
       "      <td>249.560958</td>\n",
       "      <td>...</td>\n",
       "      <td>221.406581</td>\n",
       "      <td>25.996245</td>\n",
       "      <td>25.063417</td>\n",
       "      <td>116.879514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.995546</td>\n",
       "      <td>86.905659</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>7.999881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.777249</td>\n",
       "      <td>2.656748</td>\n",
       "      <td>1.588231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.857790</td>\n",
       "      <td>329.782639</td>\n",
       "      <td>5.742023</td>\n",
       "      <td>4.866864e+03</td>\n",
       "      <td>145.999866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991087</td>\n",
       "      <td>0.170790</td>\n",
       "      <td>1.529628</td>\n",
       "      <td>1.550401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.822858</td>\n",
       "      <td>3.134117</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>3.514000e+03</td>\n",
       "      <td>71.139241</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.972973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.725000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>8.393000e+03</td>\n",
       "      <td>209.648228</td>\n",
       "      <td>...</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.963710</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>42.781524</td>\n",
       "      <td>9.287500e+03</td>\n",
       "      <td>247.208951</td>\n",
       "      <td>...</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.861955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.974322</td>\n",
       "      <td>2087.000000</td>\n",
       "      <td>49.605280</td>\n",
       "      <td>1.219300e+04</td>\n",
       "      <td>291.355050</td>\n",
       "      <td>...</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>16.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24845.951220</td>\n",
       "      <td>3443.000000</td>\n",
       "      <td>53.170732</td>\n",
       "      <td>1.047310e+06</td>\n",
       "      <td>33784.193550</td>\n",
       "      <td>...</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category  pslist.nproc  pslist.nppid  pslist.avg_threads  \\\n",
       "count     58596  58596.000000  58596.000000        58596.000000   \n",
       "unique    28346           NaN           NaN                 NaN   \n",
       "top      Benign           NaN           NaN                 NaN   \n",
       "freq      29298           NaN           NaN                 NaN   \n",
       "mean        NaN     41.394771     14.713837           11.341655   \n",
       "std         NaN      5.777249      2.656748            1.588231   \n",
       "min         NaN     21.000000      8.000000            1.650000   \n",
       "25%         NaN     40.000000     12.000000            9.972973   \n",
       "50%         NaN     41.000000     15.000000           11.000000   \n",
       "75%         NaN     43.000000     16.000000           12.861955   \n",
       "max         NaN    240.000000     72.000000           16.818182   \n",
       "\n",
       "        pslist.nprocs64bit  pslist.avg_handlers  dlllist.ndlls  \\\n",
       "count              58596.0         58596.000000   58596.000000   \n",
       "unique                 NaN                  NaN            NaN   \n",
       "top                    NaN                  NaN            NaN   \n",
       "freq                   NaN                  NaN            NaN   \n",
       "mean                   0.0           247.509819    1810.805447   \n",
       "std                    0.0           111.857790     329.782639   \n",
       "min                    0.0            34.962500     670.000000   \n",
       "25%                    0.0           208.725000    1556.000000   \n",
       "50%                    0.0           243.963710    1735.000000   \n",
       "75%                    0.0           289.974322    2087.000000   \n",
       "max                    0.0         24845.951220    3443.000000   \n",
       "\n",
       "        dlllist.avg_dlls_per_proc  handles.nhandles  \\\n",
       "count                58596.000000      5.859600e+04   \n",
       "unique                        NaN               NaN   \n",
       "top                           NaN               NaN   \n",
       "freq                          NaN               NaN   \n",
       "mean                    43.707806      1.025858e+04   \n",
       "std                      5.742023      4.866864e+03   \n",
       "min                      7.333333      3.514000e+03   \n",
       "25%                     38.833333      8.393000e+03   \n",
       "50%                     42.781524      9.287500e+03   \n",
       "75%                     49.605280      1.219300e+04   \n",
       "max                     53.170732      1.047310e+06   \n",
       "\n",
       "        handles.avg_handles_per_proc  ...  svcscan.kernel_drivers  \\\n",
       "count                   58596.000000  ...            58596.000000   \n",
       "unique                           NaN  ...                     NaN   \n",
       "top                              NaN  ...                     NaN   \n",
       "freq                             NaN  ...                     NaN   \n",
       "mean                      249.560958  ...              221.406581   \n",
       "std                       145.999866  ...                1.991087   \n",
       "min                        71.139241  ...               55.000000   \n",
       "25%                       209.648228  ...              221.000000   \n",
       "50%                       247.208951  ...              221.000000   \n",
       "75%                       291.355050  ...              222.000000   \n",
       "max                     33784.193550  ...              222.000000   \n",
       "\n",
       "        svcscan.fs_drivers  svcscan.process_services  \\\n",
       "count         58596.000000              58596.000000   \n",
       "unique                 NaN                       NaN   \n",
       "top                    NaN                       NaN   \n",
       "freq                   NaN                       NaN   \n",
       "mean             25.996245                 25.063417   \n",
       "std               0.170790                  1.529628   \n",
       "min               6.000000                  7.000000   \n",
       "25%              26.000000                 24.000000   \n",
       "50%              26.000000                 24.000000   \n",
       "75%              26.000000                 27.000000   \n",
       "max              26.000000                 27.000000   \n",
       "\n",
       "        svcscan.shared_process_services  svcscan.interactive_process_services  \\\n",
       "count                      58596.000000                               58596.0   \n",
       "unique                              NaN                                   NaN   \n",
       "top                                 NaN                                   NaN   \n",
       "freq                                NaN                                   NaN   \n",
       "mean                         116.879514                                   0.0   \n",
       "std                            1.550401                                   0.0   \n",
       "min                           26.000000                                   0.0   \n",
       "25%                          116.000000                                   0.0   \n",
       "50%                          116.000000                                   0.0   \n",
       "75%                          118.000000                                   0.0   \n",
       "max                          118.000000                                   0.0   \n",
       "\n",
       "        svcscan.nactive  callbacks.ncallbacks  callbacks.nanonymous  \\\n",
       "count      58596.000000          58596.000000          58596.000000   \n",
       "unique              NaN                   NaN                   NaN   \n",
       "top                 NaN                   NaN                   NaN   \n",
       "freq                NaN                   NaN                   NaN   \n",
       "mean         121.995546             86.905659              0.000853   \n",
       "std            2.822858              3.134117              0.029199   \n",
       "min           30.000000             50.000000              0.000000   \n",
       "25%          121.000000             87.000000              0.000000   \n",
       "50%          122.000000             87.000000              0.000000   \n",
       "75%          123.000000             88.000000              0.000000   \n",
       "max          129.000000             89.000000              1.000000   \n",
       "\n",
       "        callbacks.ngeneric   Class  \n",
       "count         58596.000000   58596  \n",
       "unique                 NaN       2  \n",
       "top                    NaN  Benign  \n",
       "freq                   NaN   29298  \n",
       "mean              7.999881     NaN  \n",
       "std               0.010929     NaN  \n",
       "min               7.000000     NaN  \n",
       "25%               8.000000     NaN  \n",
       "50%               8.000000     NaN  \n",
       "75%               8.000000     NaN  \n",
       "max               8.000000     NaN  \n",
       "\n",
       "[11 rows x 57 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan Kesimpulan Atribut Numerik\n",
    "\n",
    "DM.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231c3460-e428-41e0-846a-30628e9e2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign     29298\n",
       "Malware    29298\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DM[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36201be-227f-478d-aa2f-bd643e448805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisasi\n",
    "\n",
    "DM[\"Class\"].value_counts().plot(kind=\"pie\",autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc05e31-28ca-4eb3-8e83-35b89e2bf8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "X = DM.drop(['Category','Class'],axis=1).values    #Droping this because classification model will not accept object type elements (float and int only)\n",
    "# Target variable\n",
    "y = DM['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addcff25-7602-4329-bd43-0e3fef583b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Fitting and choosing the important variables\n",
    "extratrees = ek.ExtraTreesClassifier().fit(X,y)\n",
    "model = SelectFromModel(extratrees, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nbfeatures = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73143c08-51cc-4af9-9a08-506cf8d4ee56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of important features\n",
    "nbfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44d50ff-c11b-4050-b802-978c15bb7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c63813e-a603-4ba4-8004-5cc30709cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature handles.nhandles (0.090545)\n",
      "2. feature dlllist.avg_dlls_per_proc (0.080591)\n",
      "3. feature svcscan.shared_process_services (0.067881)\n",
      "4. feature ldrmodules.not_in_load (0.066051)\n",
      "5. feature pslist.nprocs64bit (0.060138)\n",
      "6. feature handles.ndesktop (0.059739)\n",
      "7. feature handles.ndirectory (0.053026)\n",
      "8. feature svcscan.kernel_drivers (0.051673)\n",
      "9. feature handles.nthread (0.050867)\n",
      "10. feature svcscan.interactive_process_services (0.048031)\n",
      "11. feature handles.ntimer (0.042099)\n",
      "12. feature ldrmodules.not_in_init (0.040477)\n",
      "13. feature handles.nsection (0.038445)\n",
      "14. feature callbacks.ncallbacks (0.033989)\n",
      "15. feature ldrmodules.not_in_load_avg (0.031311)\n",
      "16. feature svcscan.fs_drivers (0.024699)\n"
     ]
    }
   ],
   "source": [
    "#All the required features\n",
    "for f in range(nbfeatures):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, DM.columns[2+index[f]], extratrees.feature_importances_[index[f]]))\n",
    "    features.append(DM.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6732a2a8-9367-4b7f-b786-3a4ab10ed867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralDecisionTree(keras.Model):\n",
    "    def __init__(self, depth, num_features, used_features_rate, num_classes):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.num_leaves = 2 ** depth\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Create a mask for the randomly selected features.\n",
    "        num_used_features = int(num_features * used_features_rate)\n",
    "        one_hot = np.eye(num_features)\n",
    "        sampled_feature_indicies = np.random.choice(\n",
    "            np.arange(num_features), num_used_features, replace=False\n",
    "        )\n",
    "        self.used_features_mask = one_hot[sampled_feature_indicies]\n",
    "\n",
    "        # Initialize the weights of the classes in leaves.\n",
    "        self.pi = tf.Variable(\n",
    "            initial_value=tf.random_normal_initializer()(\n",
    "                shape=[self.num_leaves, self.num_classes]\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Initialize the stochastic routing layer.\n",
    "        self.decision_fn = layers.Dense(\n",
    "            units=self.num_leaves, activation=\"sigmoid\", name=\"decision\"\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        # Apply the feature mask to the input features.\n",
    "        features = tf.matmul(\n",
    "            features, self.used_features_mask, transpose_b=True\n",
    "        )  # [batch_size, num_used_features]\n",
    "        # Compute the routing probabilities.\n",
    "        decisions = tf.expand_dims(\n",
    "            self.decision_fn(features), axis=2\n",
    "        )  # [batch_size, num_leaves, 1]\n",
    "        # Concatenate the routing probabilities with their complements.\n",
    "        decisions = layers.concatenate(\n",
    "            [decisions, 1 - decisions], axis=2\n",
    "        )  # [batch_size, num_leaves, 2]\n",
    "\n",
    "        mu = tf.ones([batch_size, 1, 1])\n",
    "\n",
    "        begin_idx = 1\n",
    "        end_idx = 2\n",
    "        # Traverse the tree in breadth-first order.\n",
    "        for level in range(self.depth):\n",
    "            mu = tf.reshape(mu, [batch_size, -1, 1])  # [batch_size, 2 ** level, 1]\n",
    "            mu = tf.tile(mu, (1, 1, 2))  # [batch_size, 2 ** level, 2]\n",
    "            level_decisions = decisions[\n",
    "                :, begin_idx:end_idx, :\n",
    "            ]  # [batch_size, 2 ** level, 2]\n",
    "            mu = mu * level_decisions  # [batch_size, 2**level, 2]\n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (level + 1)\n",
    "\n",
    "        mu = tf.reshape(mu, [batch_size, self.num_leaves])  # [batch_size, num_leaves]\n",
    "        probabilities = keras.activations.softmax(self.pi)  # [num_leaves, num_classes]\n",
    "        outputs = tf.matmul(mu, probabilities)  # [batch_size, num_classes]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0653c334-1c8b-45af-a841-7deefe0f975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralDecisionForest(keras.Model):\n",
    "    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n",
    "        super().__init__()\n",
    "        self.ensemble = []\n",
    "        # Initialize the ensemble by adding NeuralDecisionForest instances.\n",
    "        # Each tree will have its own randomly selected input features to use.\n",
    "        for _ in range(num_trees):\n",
    "            self.ensemble.append(\n",
    "                NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "            )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Initialize the outputs: a [batch_size, num_classes] matrix of zeros.\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        outputs = tf.zeros([batch_size, num_classes])\n",
    "\n",
    "        # Aggregate the outputs of trees in the ensemble.\n",
    "        for tree in self.ensemble:\n",
    "            outputs += tree(inputs)\n",
    "        # Divide the outputs by the ensemble size to get the average.\n",
    "        outputs /= len(self.ensemble)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54acf76d-12a6-44fb-a3cb-9bdfc2e71ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 14s 16ms/step - loss: 0.2496 - sparse_categorical_accuracy: 0.9814 - val_loss: 2.5318 - val_sparse_categorical_accuracy: 0.0528\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9498\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0560 - val_sparse_categorical_accuracy: 0.9933\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0631 - val_sparse_categorical_accuracy: 0.9941\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0380 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0298 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0375 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0220 - val_sparse_categorical_accuracy: 0.9954\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 0.9954\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0296 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0364 - val_sparse_categorical_accuracy: 0.9956\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0467 - val_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0333 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0394 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0425 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0274 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0331 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0343 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0281 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0211 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0352 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0351 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0354 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0333 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0378 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0217 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0218 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0310 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0374 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0315 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0340 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0324 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0301 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0386 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0352 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0308 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0329 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0332 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0329 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0362 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0343 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0338 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0338 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0277 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0328 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0269 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0334 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0371 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0335 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0178 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0295 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9972\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9971\n",
      "Test accuracy: 99.71%\n",
      "184/184 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9971\n",
      "Precision: 0.9983\n",
      "Recall: 0.9959\n",
      "F1 Score: 0.9971\n",
      "Total Training Time: 110.22530722618103 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 14s 16ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0351 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0198 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0339 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0340 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0216 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0332 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0334 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0159 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0165 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0232 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0187 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0155 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0249 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0213 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0215 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0282 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0300 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0202 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0188 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0124 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0214 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0318 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0436 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0380 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0196 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0312 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0299 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0212 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0378 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0361 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0347 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0410 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0432 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0415 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0319 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0328 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0363 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0301 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0430 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0370 - val_sparse_categorical_accuracy: 0.9972\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9973\n",
      "Test accuracy: 99.73%\n",
      "184/184 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9973\n",
      "Precision: 0.9973\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9973\n",
      "Total Training Time: 107.86115646362305 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 14s 15ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9978\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9986\n",
      "Test accuracy: 99.86%\n",
      "184/184 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.9986\n",
      "Recall: 0.9986\n",
      "F1 Score: 0.9986\n",
      "Total Training Time: 113.31471824645996 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 14s 14ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0199 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0231 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0223 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0207 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0225 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0220 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0181 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0207 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0211 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0195 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0200 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0173 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0188 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0156 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0199 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0221 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0197 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0267 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0196 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0195 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0194 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0192 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0166 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0225 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0223 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0143 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0188 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0224 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0213 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0154 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0154 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0208 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0295 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0150 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 0.9973\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "184/184 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9983\n",
      "Recall: 0.9966\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 111.37991428375244 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 15s 16ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0210 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0174 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0185 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0151 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0277 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0215 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0150 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0153 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0185 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0150 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0164 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0195 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0179 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0270 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0194 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0279 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0259 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0191 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0098 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0310 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0235 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0282 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0207 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0139 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0172 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0312 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0225 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0132 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0281 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0259 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0176 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0178 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0156 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0224 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0229 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9967\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9993\n",
      "Test accuracy: 99.93%\n",
      "184/184 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9993\n",
      "Precision: 0.9997\n",
      "Recall: 0.9990\n",
      "F1 Score: 0.9993\n",
      "Total Training Time: 112.75075840950012 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 15s 16ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0263 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0196 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0215 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0161 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0217 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0295 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0230 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 8ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0214 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0036 - sparse_categorical_accuracy: 0.9986"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fold_results\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Run the experiment with cross-validation\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment_with_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_forest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Display average performance metrics across all folds\u001b[39;00m\n\u001b[0;32m     90\u001b[0m avg_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "Cell \u001b[1;32mIn[22], line 51\u001b[0m, in \u001b[0;36mrun_experiment_with_cv\u001b[1;34m(model, X, y, skf)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 51\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1790\u001b[0m     )\n\u001b[1;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1806\u001b[0m }\n\u001b[0;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2189\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2188\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_test_begin()\n\u001b[1;32m-> 2189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   2190\u001b[0m     _,\n\u001b[0;32m   2191\u001b[0m     dataset_or_iterator,\n\u001b[0;32m   2192\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1331\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    706\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 710\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    746\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    747\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 749\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3451\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3450\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3451\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3452\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3454\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming 'DM' is your DataFrame\n",
    "X = DM[features]\n",
    "y = (DM['Class'] == 'Malware').astype(int)\n",
    "\n",
    "# Convert y to a 1D array and make sure it's an integer array\n",
    "y = y.values.astype(int)\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 10\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "learning_rate = 0.01\n",
    "num_classes = 2  # Assuming binary classification (malware or not)\n",
    "batch_size = 265\n",
    "num_epochs = 100\n",
    "num_trees = 25\n",
    "depth = 5\n",
    "used_features_rate = 0.5\n",
    "\n",
    "# Function to create the forest model\n",
    "def create_forest_model():\n",
    "    input_shape = X.shape[1]\n",
    "    inputs = layers.Input(shape=(input_shape,))\n",
    "    normalized_inputs = layers.BatchNormalization()(inputs)\n",
    "\n",
    "    forest_model = NeuralDecisionForest(\n",
    "        num_trees, depth, input_shape, used_features_rate, num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    outputs = forest_model(normalized_inputs)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Function to run the experiment with cross-validation\n",
    "def run_experiment_with_cv(model, X, y, skf):\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\nFold {fold}:\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "\n",
    "        print(\"Start training the model...\")\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)\n",
    "        end_time = time.time()\n",
    "        print(\"Model training finished\")\n",
    "\n",
    "        print(\"Evaluating the model on the test data...\")\n",
    "        _, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "        y_test = y_test.astype(int)\n",
    "        y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        training_time = end_time - start_time\n",
    "        print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "        fold_results.append({\n",
    "            \"fold\": fold,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"training_time\": training_time,\n",
    "        })\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "# Run the experiment with cross-validation\n",
    "results = run_experiment_with_cv(create_forest_model(), X, y, skf)\n",
    "\n",
    "# Display average performance metrics across all folds\n",
    "avg_accuracy = np.mean([result[\"accuracy\"] for result in results])\n",
    "avg_precision = np.mean([result[\"precision\"] for result in results])\n",
    "avg_recall = np.mean([result[\"recall\"] for result in results])\n",
    "avg_f1 = np.mean([result[\"f1\"] for result in results])\n",
    "avg_training_time = np.mean([result[\"training_time\"] for result in results])\n",
    "\n",
    "print(\"\\nAverage Performance Metrics Across Folds:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Training Time: {avg_training_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a02ca813-d10c-45a5-9b8d-8405ec27c905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "89/89 [==============================] - 14s 23ms/step - loss: 0.3674 - sparse_categorical_accuracy: 0.9797 - val_loss: 2.2875 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9896 - val_loss: 1.9477 - val_sparse_categorical_accuracy: 0.0619\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.1858 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0174 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.0143 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 0.9964\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "916/916 [==============================] - 1s 1ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9955\n",
      "Test accuracy: 99.55%\n",
      "916/916 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9955\n",
      "Precision: 0.9951\n",
      "Recall: 0.9958\n",
      "F1 Score: 0.9955\n",
      "Total Training Time: 19.422467947006226 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "89/89 [==============================] - 13s 24ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 2/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 3/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0437 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 5/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0421 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0351 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 0.9981\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "916/916 [==============================] - 1s 1ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n",
      "916/916 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9969\n",
      "Recall: 0.9972\n",
      "F1 Score: 0.9970\n",
      "Total Training Time: 18.58590078353882 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9962\n",
      "Average Precision: 0.9960\n",
      "Average Recall: 0.9965\n",
      "Average F1 Score: 0.9962\n",
      "Average Training Time: 19.0042 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 14s 20ms/step - loss: 0.3052 - sparse_categorical_accuracy: 0.9820 - val_loss: 2.5511 - val_sparse_categorical_accuracy: 0.0020\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.7050\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0463 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9946\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0104 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0094 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9965\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9955\n",
      "Test accuracy: 99.55%\n",
      "611/611 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9955\n",
      "Precision: 0.9957\n",
      "Recall: 0.9954\n",
      "F1 Score: 0.9955\n",
      "Total Training Time: 20.11354970932007 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 13s 19ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0699 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0548 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0464 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0457 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0446 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0447 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0314 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0304 - val_sparse_categorical_accuracy: 0.9983\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "611/611 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9973\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 20.124184370040894 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 14s 19ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0282 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0203 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0232 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0207 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0260 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n",
      "611/611 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9972\n",
      "Recall: 0.9967\n",
      "F1 Score: 0.9970\n",
      "Total Training Time: 21.360283374786377 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9967\n",
      "Average Precision: 0.9968\n",
      "Average Recall: 0.9966\n",
      "Average F1 Score: 0.9967\n",
      "Average Training Time: 20.5327 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 15s 18ms/step - loss: 0.2828 - sparse_categorical_accuracy: 0.9818 - val_loss: 2.7227 - val_sparse_categorical_accuracy: 0.0122\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.2264 - val_sparse_categorical_accuracy: 0.9159\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 1s 8ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9956\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0139 - val_sparse_categorical_accuracy: 0.9958\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 8ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9992\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9965\n",
      "Test accuracy: 99.65%\n",
      "458/458 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9958\n",
      "Recall: 0.9971\n",
      "F1 Score: 0.9965\n",
      "Total Training Time: 24.07773494720459 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 13s 17ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0274 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0187 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0123 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0172 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0166 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 7ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9984\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "458/458 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9971\n",
      "Recall: 0.9977\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 21.77721118927002 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 14s 19ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 10ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 8ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0119 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0151 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9984\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9965\n",
      "Test accuracy: 99.65%\n",
      "458/458 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9962\n",
      "Recall: 0.9969\n",
      "F1 Score: 0.9965\n",
      "Total Training Time: 24.495210886001587 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 15s 33ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0124 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0105 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 0.9983\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
      "Test accuracy: 99.76%\n",
      "458/458 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9976\n",
      "Precision: 0.9974\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9976\n",
      "Total Training Time: 32.23565864562988 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9970\n",
      "Average Precision: 0.9966\n",
      "Average Recall: 0.9974\n",
      "Average F1 Score: 0.9970\n",
      "Average Training Time: 25.6465 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 15s 25ms/step - loss: 0.2705 - sparse_categorical_accuracy: 0.9818 - val_loss: 2.7185 - val_sparse_categorical_accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.4052 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0499 - val_sparse_categorical_accuracy: 0.9941\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0462 - val_sparse_categorical_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0283 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0335 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0300 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0225 - val_sparse_categorical_accuracy: 0.9982\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9967\n",
      "Test accuracy: 99.67%\n",
      "367/367 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9967\n",
      "Precision: 0.9971\n",
      "Recall: 0.9962\n",
      "F1 Score: 0.9967\n",
      "Total Training Time: 34.173441648483276 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 15s 28ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 0.9985\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 2s 18ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9987\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n",
      "367/367 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9961\n",
      "Recall: 0.9980\n",
      "F1 Score: 0.9970\n",
      "Total Training Time: 36.83954215049744 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 16s 28ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0188 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0181 - val_sparse_categorical_accuracy: 0.9974\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9980\n",
      "Test accuracy: 99.8%\n",
      "367/367 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9980\n",
      "Precision: 0.9983\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9980\n",
      "Total Training Time: 41.382086753845215 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 15s 29ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0160 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0153 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0210 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0166 - val_sparse_categorical_accuracy: 0.9973\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "367/367 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9976\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 39.20781683921814 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 15s 28ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0197 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 2s 18ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0191 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0189 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0187 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0158 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0216 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "367/367 [==============================] - 2s 1ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9991\n",
      "Recall: 0.9964\n",
      "F1 Score: 0.9978\n",
      "Total Training Time: 37.452024698257446 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9974\n",
      "Average Precision: 0.9976\n",
      "Average Recall: 0.9971\n",
      "Average F1 Score: 0.9974\n",
      "Average Training Time: 37.8110 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 15s 28ms/step - loss: 0.2637 - sparse_categorical_accuracy: 0.9798 - val_loss: 2.4600 - val_sparse_categorical_accuracy: 0.0461\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.3676 - val_sparse_categorical_accuracy: 0.8441\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0730 - val_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.0590 - val_sparse_categorical_accuracy: 0.9941\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0396 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.0294 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0189 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9981\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0169 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9975\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 37.63679242134094 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 19s 32ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9988\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9966\n",
      "Test accuracy: 99.66%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9966\n",
      "Precision: 0.9961\n",
      "Recall: 0.9971\n",
      "F1 Score: 0.9966\n",
      "Total Training Time: 43.680169343948364 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 16s 27ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0148 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0148 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0139 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0154 - val_sparse_categorical_accuracy: 0.9973\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9975\n",
      "Recall: 0.9982\n",
      "F1 Score: 0.9979\n",
      "Total Training Time: 38.604604959487915 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 15s 26ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0141 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0098 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 0.9970\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9988\n",
      "Recall: 0.9963\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 36.359997272491455 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 16s 26ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0104 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 2s 15ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0100 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 2s 15ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 2s 15ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0111 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 2s 15ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9972\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9973\n",
      "Test accuracy: 99.73%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9973\n",
      "Precision: 0.9977\n",
      "Recall: 0.9969\n",
      "F1 Score: 0.9973\n",
      "Total Training Time: 36.652419090270996 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "148/148 [==============================] - 17s 27ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0127 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0111 - val_sparse_categorical_accuracy: 0.9969\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
      "Test accuracy: 99.72%\n",
      "306/306 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9972\n",
      "Precision: 0.9998\n",
      "Recall: 0.9947\n",
      "F1 Score: 0.9972\n",
      "Total Training Time: 40.810582637786865 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9973\n",
      "Average Precision: 0.9979\n",
      "Average Recall: 0.9968\n",
      "Average F1 Score: 0.9973\n",
      "Average Training Time: 38.9574 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 16s 33ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.9824 - val_loss: 2.7781 - val_sparse_categorical_accuracy: 0.0228\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.3225 - val_sparse_categorical_accuracy: 0.8786\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0603 - val_sparse_categorical_accuracy: 0.9937\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0387 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0512 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0509 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0600 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 0.9981\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 2ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9967\n",
      "Test accuracy: 99.67%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9967\n",
      "Precision: 0.9969\n",
      "Recall: 0.9964\n",
      "F1 Score: 0.9967\n",
      "Total Training Time: 47.85779881477356 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 16s 35ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9991\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 2ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9969\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 50.95729851722717 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 19s 35ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0206 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0188 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0250 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0216 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0151 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9971\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 54.64429759979248 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 17s 34ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0220 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0294 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9974\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 2ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9986\n",
      "Test accuracy: 99.86%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.9986\n",
      "Recall: 0.9986\n",
      "F1 Score: 0.9986\n",
      "Total Training Time: 48.57032632827759 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 15s 33ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0328 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0231 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0250 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9978\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 2ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9976\n",
      "Recall: 0.9964\n",
      "F1 Score: 0.9970\n",
      "Total Training Time: 47.21609425544739 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 15s 32ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0224 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0223 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0228 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0232 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 2ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9978\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9978\n",
      "Total Training Time: 47.76340413093567 seconds\n",
      "\n",
      "Fold 7:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 20s 41ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0253 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0211 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0218 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0210 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9976\n",
      "Test accuracy: 99.76%\n",
      "262/262 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9976\n",
      "Precision: 0.9978\n",
      "Recall: 0.9974\n",
      "F1 Score: 0.9976\n",
      "Total Training Time: 57.4505295753479 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9975\n",
      "Average Precision: 0.9975\n",
      "Average Recall: 0.9975\n",
      "Average F1 Score: 0.9975\n",
      "Average Training Time: 50.6371 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 19s 46ms/step - loss: 0.2546 - sparse_categorical_accuracy: 0.9825 - val_loss: 2.5540 - val_sparse_categorical_accuracy: 0.0337\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 35ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.2956 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0656 - val_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0355 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0232 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 5s 34ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0161 - val_sparse_categorical_accuracy: 0.9980\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9966\n",
      "Test accuracy: 99.66%\n",
      "229/229 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9966\n",
      "Precision: 0.9967\n",
      "Recall: 0.9965\n",
      "F1 Score: 0.9966\n",
      "Total Training Time: 66.70079302787781 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 18s 46ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0052 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9985\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 6s 38ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 6s 38ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 0.9985\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9977\n",
      "Test accuracy: 99.77%\n",
      "229/229 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9977\n",
      "Precision: 0.9973\n",
      "Recall: 0.9981\n",
      "F1 Score: 0.9977\n",
      "Total Training Time: 69.81999444961548 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 18s 50ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0185 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0161 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0151 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0138 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0104 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9965\n",
      "Test accuracy: 99.65%\n",
      "229/229 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9962\n",
      "Recall: 0.9967\n",
      "F1 Score: 0.9965\n",
      "Total Training Time: 73.14980816841125 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 20s 41ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0138 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0178 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0131 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0175 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9974\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9986\n",
      "Test accuracy: 99.86%\n",
      "229/229 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.9986\n",
      "Recall: 0.9986\n",
      "F1 Score: 0.9986\n",
      "Total Training Time: 64.24763298034668 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 17s 40ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0183 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0174 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 5s 32ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0138 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0106 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "229/229 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9984\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9978\n",
      "Total Training Time: 59.901169776916504 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 17s 40ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0118 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0118 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0110 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0098 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 0.9970\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9965\n",
      "Test accuracy: 99.65%\n",
      "229/229 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9970\n",
      "Recall: 0.9959\n",
      "F1 Score: 0.9964\n",
      "Total Training Time: 59.15614438056946 seconds\n",
      "\n",
      "Fold 7:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 17s 39ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0187 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0154 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0176 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0127 - val_sparse_categorical_accuracy: 0.9974\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 3ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9981\n",
      "Test accuracy: 99.81%\n",
      "229/229 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9981\n",
      "Precision: 0.9992\n",
      "Recall: 0.9970\n",
      "F1 Score: 0.9981\n",
      "Total Training Time: 58.44178032875061 seconds\n",
      "\n",
      "Fold 8:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 18s 39ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 5s 29ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 4s 29ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 4s 29ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 4s 29ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 4s 29ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 5s 29ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0169 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 5s 29ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 5s 29ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0118 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 4s 29ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0132 - val_sparse_categorical_accuracy: 0.9978\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "229/229 [==============================] - 1s 2ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "229/229 [==============================] - 2s 2ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9978\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 58.729711055755615 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9974\n",
      "Average Precision: 0.9976\n",
      "Average Recall: 0.9972\n",
      "Average F1 Score: 0.9974\n",
      "Average Training Time: 63.7684 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 20s 55ms/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9810 - val_loss: 2.5726 - val_sparse_categorical_accuracy: 0.0514\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.2086 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0729 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9947\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0260 - val_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9985\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9960\n",
      "Test accuracy: 99.6%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9960\n",
      "Precision: 0.9957\n",
      "Recall: 0.9963\n",
      "F1 Score: 0.9960\n",
      "Total Training Time: 76.75025463104248 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 20s 56ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0126 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 8s 48ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0110 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0097 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 8s 48ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9975\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 87.45552110671997 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 21s 62ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 8s 51ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 8s 49ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 8s 49ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 8s 50ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 8s 49ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 8s 49ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 8s 50ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 8s 49ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 8s 51ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9987\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "204/204 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9978\n",
      "Recall: 0.9972\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 92.24793362617493 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 23s 51ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 7s 41ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0096 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 7s 41ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 7s 41ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 7s 41ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 0.9984\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9975\n",
      "Test accuracy: 99.75%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9975\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9975\n",
      "Total Training Time: 81.66598701477051 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 19s 50ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9983\n",
      "Test accuracy: 99.83%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9983\n",
      "Precision: 0.9975\n",
      "Recall: 0.9991\n",
      "F1 Score: 0.9983\n",
      "Total Training Time: 76.32394170761108 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 19s 49ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 0.9983\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9980\n",
      "Test accuracy: 99.8%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9980\n",
      "Precision: 0.9982\n",
      "Recall: 0.9979\n",
      "F1 Score: 0.9980\n",
      "Total Training Time: 76.02279210090637 seconds\n",
      "\n",
      "Fold 7:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 19s 49ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 7s 43ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9966\n",
      "Test accuracy: 99.66%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9966\n",
      "Precision: 0.9966\n",
      "Recall: 0.9966\n",
      "F1 Score: 0.9966\n",
      "Total Training Time: 75.47617030143738 seconds\n",
      "\n",
      "Fold 8:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 18s 48ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0064 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9983\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9982\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9978\n",
      "Total Training Time: 73.59110617637634 seconds\n",
      "\n",
      "Fold 9:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 20s 51ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 7s 43ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 0.9978\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9980\n",
      "Test accuracy: 99.8%\n",
      "204/204 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9980\n",
      "Precision: 0.9982\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9980\n",
      "Total Training Time: 80.19180631637573 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9975\n",
      "Average Precision: 0.9975\n",
      "Average Recall: 0.9975\n",
      "Average F1 Score: 0.9975\n",
      "Average Training Time: 79.9695 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 21s 60ms/step - loss: 0.2493 - sparse_categorical_accuracy: 0.9733 - val_loss: 2.5506 - val_sparse_categorical_accuracy: 0.0523\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9571\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0681 - val_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 8s 52ms/step - loss: 0.0178 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0330 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0210 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 8s 52ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 8s 51ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0183 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 8s 50ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0104 - val_sparse_categorical_accuracy: 0.9982\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9962\n",
      "Test accuracy: 99.62%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9962\n",
      "Precision: 0.9966\n",
      "Recall: 0.9959\n",
      "F1 Score: 0.9962\n",
      "Total Training Time: 94.33241868019104 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 23s 69ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0141 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0176 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0105 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0119 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0166 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9973\n",
      "Test accuracy: 99.73%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9973\n",
      "Precision: 0.9969\n",
      "Recall: 0.9976\n",
      "F1 Score: 0.9973\n",
      "Total Training Time: 108.48053979873657 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 23s 73ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 10s 63ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9983\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9978\n",
      "Test accuracy: 99.78%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.9980\n",
      "Recall: 0.9976\n",
      "F1 Score: 0.9978\n",
      "Total Training Time: 113.62155222892761 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 24s 55ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0082 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0095 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9964\n",
      "Test accuracy: 99.64%\n",
      "184/184 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9964\n",
      "Precision: 0.9962\n",
      "Recall: 0.9966\n",
      "F1 Score: 0.9964\n",
      "Total Training Time: 89.35717296600342 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 20s 54ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0107 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0095 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
      "Test accuracy: 99.88%\n",
      "184/184 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9988\n",
      "Precision: 0.9986\n",
      "Recall: 0.9990\n",
      "F1 Score: 0.9988\n",
      "Total Training Time: 82.97142171859741 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 20s 53ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9985\n",
      "Test accuracy: 99.85%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9985\n",
      "Precision: 0.9983\n",
      "Recall: 0.9986\n",
      "F1 Score: 0.9985\n",
      "Total Training Time: 82.43765711784363 seconds\n",
      "\n",
      "Fold 7:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 20s 52ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 42ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9969\n",
      "Test accuracy: 99.69%\n",
      "184/184 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9969\n",
      "Precision: 0.9976\n",
      "Recall: 0.9962\n",
      "F1 Score: 0.9969\n",
      "Total Training Time: 81.50917744636536 seconds\n",
      "\n",
      "Fold 8:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 19s 53ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9975\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
      "Test accuracy: 99.74%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9976\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9974\n",
      "Total Training Time: 82.2744927406311 seconds\n",
      "\n",
      "Fold 9:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 22s 55ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0064 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 7s 45ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 7s 47ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 7s 47ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 7s 47ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 7s 47ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 7s 46ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9981\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
      "Test accuracy: 99.81%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9981\n",
      "Precision: 0.9993\n",
      "Recall: 0.9969\n",
      "F1 Score: 0.9981\n",
      "Total Training Time: 88.36011576652527 seconds\n",
      "\n",
      "Fold 10:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 22s 69ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0091 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9975\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "184/184 [==============================] - 1s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9983\n",
      "Test accuracy: 99.83%\n",
      "184/184 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9983\n",
      "Precision: 0.9983\n",
      "Recall: 0.9983\n",
      "F1 Score: 0.9983\n",
      "Total Training Time: 106.97639751434326 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9976\n",
      "Average Precision: 0.9977\n",
      "Average Recall: 0.9974\n",
      "Average F1 Score: 0.9976\n",
      "Average Training Time: 93.0321 seconds\n",
      "\n",
      "Fold 1:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 23s 75ms/step - loss: 0.2477 - sparse_categorical_accuracy: 0.9766 - val_loss: 2.3774 - val_sparse_categorical_accuracy: 0.0532\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.1573 - val_sparse_categorical_accuracy: 0.9862\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0297 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0491 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9954\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0181 - val_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 11s 65ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9956\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9951\n",
      "Test accuracy: 99.51%\n",
      "167/167 [==============================] - 2s 5ms/step\n",
      "Accuracy: 0.9951\n",
      "Precision: 0.9966\n",
      "Recall: 0.9936\n",
      "F1 Score: 0.9951\n",
      "Total Training Time: 119.54543685913086 seconds\n",
      "\n",
      "Fold 2:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 24s 79ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0175 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 11s 71ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0157 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 11s 70ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 11s 70ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 11s 71ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 11s 71ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0148 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 11s 70ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 11s 70ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 11s 71ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 12s 71ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9985\n",
      "Test accuracy: 99.85%\n",
      "167/167 [==============================] - 2s 5ms/step\n",
      "Accuracy: 0.9985\n",
      "Precision: 0.9978\n",
      "Recall: 0.9992\n",
      "F1 Score: 0.9985\n",
      "Total Training Time: 126.15954184532166 seconds\n",
      "\n",
      "Fold 3:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 25s 53ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 7s 44ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 7s 44ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9987\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9985\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9986\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9970\n",
      "Test accuracy: 99.7%\n",
      "167/167 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9970\n",
      "Precision: 0.9966\n",
      "Recall: 0.9974\n",
      "F1 Score: 0.9970\n",
      "Total Training Time: 87.88419389724731 seconds\n",
      "\n",
      "Fold 4:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 19s 51ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0150 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0158 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0177 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0159 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0143 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0175 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0165 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0164 - val_sparse_categorical_accuracy: 0.9979\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9962\n",
      "Test accuracy: 99.62%\n",
      "167/167 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9962\n",
      "Precision: 0.9959\n",
      "Recall: 0.9966\n",
      "F1 Score: 0.9962\n",
      "Total Training Time: 80.0641462802887 seconds\n",
      "\n",
      "Fold 5:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 19s 50ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0192 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0199 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0159 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0214 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 0.9975\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9994\n",
      "Test accuracy: 99.94%\n",
      "167/167 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9994\n",
      "Precision: 0.9996\n",
      "Recall: 0.9992\n",
      "F1 Score: 0.9994\n",
      "Total Training Time: 78.92307829856873 seconds\n",
      "\n",
      "Fold 6:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 19s 50ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0132 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 7s 45ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 8s 48ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 7s 42ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9981\n",
      "Test accuracy: 99.81%\n",
      "167/167 [==============================] - 3s 5ms/step\n",
      "Accuracy: 0.9981\n",
      "Precision: 0.9977\n",
      "Recall: 0.9985\n",
      "F1 Score: 0.9981\n",
      "Total Training Time: 81.26051330566406 seconds\n",
      "\n",
      "Fold 7:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 21s 49ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0123 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 7s 41ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 7s 46ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 7s 45ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0151 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0131 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0133 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9981\n",
      "Test accuracy: 99.81%\n",
      "167/167 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9981\n",
      "Precision: 0.9992\n",
      "Recall: 0.9970\n",
      "F1 Score: 0.9981\n",
      "Total Training Time: 80.32051086425781 seconds\n",
      "\n",
      "Fold 8:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 21s 49ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0123 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0124 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0157 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 6s 40ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 6s 39ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 0.9975\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9962\n",
      "Test accuracy: 99.62%\n",
      "167/167 [==============================] - 2s 3ms/step\n",
      "Accuracy: 0.9962\n",
      "Precision: 0.9962\n",
      "Recall: 0.9962\n",
      "F1 Score: 0.9962\n",
      "Total Training Time: 78.49032974243164 seconds\n",
      "\n",
      "Fold 9:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 23s 70ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0118 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 9s 59ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 9s 58ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 10s 60ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0156 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0110 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 10s 59ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0113 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 9s 58ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 9s 59ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0123 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 9s 58ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0119 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 9s 59ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 0.9976\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9985\n",
      "Test accuracy: 99.85%\n",
      "167/167 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9985\n",
      "Precision: 0.9992\n",
      "Recall: 0.9977\n",
      "F1 Score: 0.9985\n",
      "Total Training Time: 108.96555733680725 seconds\n",
      "\n",
      "Fold 10:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 25s 77ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 11s 70ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0124 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 11s 68ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0119 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 11s 69ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0145 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 11s 69ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 12s 72ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 10s 63ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 10s 62ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0141 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 10s 62ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 10s 62ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9977\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9979\n",
      "Test accuracy: 99.79%\n",
      "167/167 [==============================] - 2s 4ms/step\n",
      "Accuracy: 0.9979\n",
      "Precision: 1.0000\n",
      "Recall: 0.9959\n",
      "F1 Score: 0.9979\n",
      "Total Training Time: 121.4229850769043 seconds\n",
      "\n",
      "Fold 11:\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "161/161 [==============================] - 24s 78ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0126 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 11s 68ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0120 - val_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 11s 68ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 11s 68ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 11s 68ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 12s 73ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0148 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 11s 71ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0171 - val_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 12s 72ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0159 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 12s 72ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0161 - val_sparse_categorical_accuracy: 0.9971\n",
      "Model training finished\n",
      "Evaluating the model on the test data...\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9987\n",
      "Test accuracy: 99.87%\n",
      "167/167 [==============================] - 2s 5ms/step\n",
      "Accuracy: 0.9987\n",
      "Precision: 0.9989\n",
      "Recall: 0.9985\n",
      "F1 Score: 0.9987\n",
      "Total Training Time: 125.61205053329468 seconds\n",
      "\n",
      "Average Performance Metrics Across Folds:\n",
      "Average Accuracy: 0.9976\n",
      "Average Precision: 0.9980\n",
      "Average Recall: 0.9973\n",
      "Average F1 Score: 0.9976\n",
      "Average Training Time: 98.9680 seconds\n"
     ]
    }
   ],
   "source": [
    "# Coba berbagai fold agar lebih banyak data\n",
    "\n",
    "hasilFold = []\n",
    "print(\"test\")\n",
    "\n",
    "for num_folds in range(2,12):\n",
    "  # Assuming 'DM' is your DataFrame\n",
    "    X = DM[features]\n",
    "    y = (DM['Class'] == 'Malware').astype(int)\n",
    "    \n",
    "    # Convert y to a 1D array and make sure it's an integer array\n",
    "    y = y.values.astype(int)\n",
    "    \n",
    "    # Define the number of folds\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    learning_rate = 0.01\n",
    "    num_classes = 2  # Assuming binary classification (malware or not)\n",
    "    batch_size = 265\n",
    "    num_epochs = 10\n",
    "    num_trees = 25\n",
    "    depth = 5\n",
    "    used_features_rate = 0.5\n",
    "    \n",
    "    # Function to create the forest model\n",
    "    def create_forest_model():\n",
    "        input_shape = X.shape[1]\n",
    "        inputs = layers.Input(shape=(input_shape,))\n",
    "        normalized_inputs = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "        forest_model = NeuralDecisionForest(\n",
    "            num_trees, depth, input_shape, used_features_rate, num_classes=num_classes\n",
    "        )\n",
    "    \n",
    "        outputs = forest_model(normalized_inputs)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    # Function to run the experiment with cross-validation\n",
    "    def run_experiment_with_cv(model, X, y, skf):\n",
    "        fold_results = []\n",
    "    \n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "            print(f\"\\nFold {fold}:\")\n",
    "    \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "            model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "            )\n",
    "    \n",
    "            print(\"Start training the model...\")\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)\n",
    "            end_time = time.time()\n",
    "            print(\"Model training finished\")\n",
    "    \n",
    "            print(\"Evaluating the model on the test data...\")\n",
    "            _, accuracy = model.evaluate(X_test, y_test)\n",
    "            print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    \n",
    "            y_test = y_test.astype(int)\n",
    "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "            training_time = end_time - start_time\n",
    "            print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "    \n",
    "            fold_results.append({\n",
    "                \"fold\": fold,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1,\n",
    "                \"training_time\": training_time,\n",
    "            })\n",
    "    \n",
    "        return fold_results\n",
    "    \n",
    "    # Run the experiment with cross-validation\n",
    "    results = run_experiment_with_cv(create_forest_model(), X, y, skf)\n",
    "    \n",
    "    # Display average performance metrics across all folds\n",
    "    avg_accuracy = np.mean([result[\"accuracy\"] for result in results])\n",
    "    avg_precision = np.mean([result[\"precision\"] for result in results])\n",
    "    avg_recall = np.mean([result[\"recall\"] for result in results])\n",
    "    avg_f1 = np.mean([result[\"f1\"] for result in results])\n",
    "    avg_training_time = np.mean([result[\"training_time\"] for result in results])\n",
    "    \n",
    "    print(\"\\nAverage Performance Metrics Across Folds:\")\n",
    "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "    print(f\"Average Training Time: {avg_training_time:.4f} seconds\")  \n",
    "\n",
    "    matrix = [[num_folds],[avg_accuracy],[avg_precision],[avg_recall],[avg_f1],[avg_training_time]]\n",
    "    hasilFold.append(matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2c63189-7f5a-4273-aefa-0e3ddb6b378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10], [0.9975766345291832], [0.9977468446023752], [0.9974059219503216], [0.9975761562152614], [93.03209459781647]]\n"
     ]
    }
   ],
   "source": [
    "winner = [[0],[0],[0],[0],[0],[0]]\n",
    "for x in range(0,(len(hasilFold)-1)):\n",
    "    i = hasilFold[x]\n",
    "    if i[1] >= winner[1]:\n",
    "        winner = i\n",
    "print(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2651df93-4fd1-406a-a4b9-9b7c88560734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot, sumbu x treshold dan sumbu y nya akurasinya\n",
    "# Pisahkan hasil menjadi list berdasarkan kolom\n",
    "num_folds, accuracy, precision, recall, f1_score, training_time = zip(*hasilFold)\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_folds, accuracy, label='Accuracy')\n",
    "#plt.plot(num_folds, precision, label='Precision')\n",
    "#plt.plot(num_folds, recall, label='Recall')\n",
    "#plt.plot(num_folds, f1_score, label='F1 Score')\n",
    "#plt.plot(num_folds, training_time, label='Training Time')\n",
    "\n",
    "plt.title('Metrics vs. Folds')\n",
    "plt.xlabel('Folds')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfafdf-5a1e-4d87-b035-df663002924a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
